{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b15f2e",
   "metadata": {},
   "source": [
    "# Run a trained policy\n",
    "\n",
    "This notebook will provide examples on how to run a trained policy and visualize the rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000a4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_38' (/home/krishnans/carbgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /home/krishnans/carbgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n",
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/krishnans/ngc/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import isaacgym\n",
    "import isaacgymenvs\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "plt_root = Path(\"../../../policy_learning_toolkit/\").expanduser()\n",
    "igenvs_root = Path(\"~/diff_manip/external/IsaacGymEnvs\").expanduser()\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import isaacgym\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy\n",
    "\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427159",
   "metadata": {},
   "source": [
    "### Download policy checkpoint\n",
    "First, let's try downloading a pretrained model from our model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfdfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained checkpooint from the model zoo\n",
    "\n",
    "ckpt_path = \"lift_ph_low_dim_epoch_1000_succ_100.pth\"\n",
    "# Lift (Proficient Human)\n",
    "urllib.request.urlretrieve(\n",
    "    \"http://downloads.cs.stanford.edu/downloads/rt_benchmark/model_zoo/lift/bc_rnn/lift_ph_low_dim_epoch_1000_succ_100.pth\",\n",
    "    filename=ckpt_path\n",
    ")\n",
    "\n",
    "assert os.path.exists(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30d5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../../bc_trained_models/test/20240403143734/models/model_epoch_2000.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c25c6",
   "metadata": {},
   "source": [
    "### Loading trained policy\n",
    "We have a convenient function called `policy_from_checkpoint` that takes care of building the correct model from the checkpoint and load the trained weights. Of course you could also load the checkpoint manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf84aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Loaded Config =============\n",
      "{\n",
      "    \"algo_name\": \"bc\",\n",
      "    \"experiment\": {\n",
      "        \"name\": \"test\",\n",
      "        \"validate\": false,\n",
      "        \"logging\": {\n",
      "            \"terminal_output_to_txt\": true,\n",
      "            \"log_tb\": true,\n",
      "            \"log_wandb\": false,\n",
      "            \"wandb_proj_name\": \"debug\"\n",
      "        },\n",
      "        \"mse\": {\n",
      "            \"enabled\": false,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"on_save_ckpt\": true,\n",
      "            \"num_samples\": 20,\n",
      "            \"visualize\": true\n",
      "        },\n",
      "        \"save\": {\n",
      "            \"enabled\": true,\n",
      "            \"every_n_seconds\": null,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"epochs\": [],\n",
      "            \"on_best_validation\": false,\n",
      "            \"on_best_rollout_return\": false,\n",
      "            \"on_best_rollout_success_rate\": true\n",
      "        },\n",
      "        \"epoch_every_n_steps\": 100,\n",
      "        \"validation_epoch_every_n_steps\": 10,\n",
      "        \"env\": null,\n",
      "        \"additional_envs\": null,\n",
      "        \"render\": false,\n",
      "        \"render_video\": true,\n",
      "        \"keep_all_videos\": false,\n",
      "        \"video_skip\": 5,\n",
      "        \"rollout\": {\n",
      "            \"enabled\": false,\n",
      "            \"n\": 50,\n",
      "            \"horizon\": 400,\n",
      "            \"rate\": 50,\n",
      "            \"warmstart\": 0,\n",
      "            \"terminate_on_success\": true,\n",
      "            \"batched\": false,\n",
      "            \"num_batch_envs\": 5\n",
      "        },\n",
      "        \"env_meta_update_dict\": {},\n",
      "        \"ckpt_path\": null\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"path\": \"../../../policy_learning_toolkit/datasets/articulate_multi_spray_scissors/train/merge_robosuite.hdf5\"\n",
      "            }\n",
      "        ],\n",
      "        \"output_dir\": \"../bc_trained_models\",\n",
      "        \"num_data_workers\": 0,\n",
      "        \"hdf5_cache_mode\": \"all\",\n",
      "        \"hdf5_use_swmr\": true,\n",
      "        \"hdf5_load_next_obs\": false,\n",
      "        \"hdf5_normalize_obs\": false,\n",
      "        \"hdf5_filter_key\": null,\n",
      "        \"hdf5_validation_filter_key\": null,\n",
      "        \"seq_length\": 1,\n",
      "        \"pad_seq_length\": true,\n",
      "        \"frame_stack\": 1,\n",
      "        \"pad_frame_stack\": true,\n",
      "        \"dataset_keys\": [\n",
      "            \"actions\"\n",
      "        ],\n",
      "        \"action_keys\": [\n",
      "            \"actions\"\n",
      "        ],\n",
      "        \"action_config\": {\n",
      "            \"actions\": {\n",
      "                \"type\": \"continuous\",\n",
      "                \"dim\": 22\n",
      "            }\n",
      "        },\n",
      "        \"goal_mode\": null,\n",
      "        \"cuda\": true,\n",
      "        \"batch_size\": 100,\n",
      "        \"num_epochs\": 2000,\n",
      "        \"seed\": 1,\n",
      "        \"max_grad_norm\": null,\n",
      "        \"data_format\": \"robomimic\",\n",
      "        \"load_env_meta\": false,\n",
      "        \"shuffled_obs_key_groups\": null\n",
      "    },\n",
      "    \"algo\": {\n",
      "        \"optim_params\": {\n",
      "            \"policy\": {\n",
      "                \"optimizer_type\": \"adam\",\n",
      "                \"learning_rate\": {\n",
      "                    \"initial\": 0.0001,\n",
      "                    \"decay_factor\": 0.1,\n",
      "                    \"epoch_schedule\": [],\n",
      "                    \"scheduler_type\": \"multistep\"\n",
      "                },\n",
      "                \"regularization\": {\n",
      "                    \"L2\": 0.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"loss\": {\n",
      "            \"l2_weight\": 1.0,\n",
      "            \"l1_weight\": 0.0,\n",
      "            \"cos_weight\": 0.0\n",
      "        },\n",
      "        \"actor_layer_dims\": [\n",
      "            1024,\n",
      "            1024\n",
      "        ],\n",
      "        \"gaussian\": {\n",
      "            \"enabled\": false,\n",
      "            \"fixed_std\": false,\n",
      "            \"init_std\": 0.1,\n",
      "            \"min_std\": 0.01,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"gmm\": {\n",
      "            \"enabled\": false,\n",
      "            \"num_modes\": 5,\n",
      "            \"min_std\": 0.0001,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"vae\": {\n",
      "            \"enabled\": false,\n",
      "            \"latent_dim\": 14,\n",
      "            \"latent_clip\": null,\n",
      "            \"kl_weight\": 1.0,\n",
      "            \"decoder\": {\n",
      "                \"is_conditioned\": true,\n",
      "                \"reconstruction_sum_across_elements\": false\n",
      "            },\n",
      "            \"prior\": {\n",
      "                \"learn\": false,\n",
      "                \"is_conditioned\": false,\n",
      "                \"use_gmm\": false,\n",
      "                \"gmm_num_modes\": 10,\n",
      "                \"gmm_learn_weights\": false,\n",
      "                \"use_categorical\": false,\n",
      "                \"categorical_dim\": 10,\n",
      "                \"categorical_gumbel_softmax_hard\": false,\n",
      "                \"categorical_init_temp\": 1.0,\n",
      "                \"categorical_temp_anneal_step\": 0.001,\n",
      "                \"categorical_min_temp\": 0.3\n",
      "            },\n",
      "            \"encoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"decoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"prior_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ]\n",
      "        },\n",
      "        \"rnn\": {\n",
      "            \"enabled\": false,\n",
      "            \"horizon\": 10,\n",
      "            \"hidden_dim\": 400,\n",
      "            \"rnn_type\": \"LSTM\",\n",
      "            \"num_layers\": 2,\n",
      "            \"open_loop\": false,\n",
      "            \"kwargs\": {\n",
      "                \"bidirectional\": false\n",
      "            }\n",
      "        },\n",
      "        \"transformer\": {\n",
      "            \"enabled\": false,\n",
      "            \"context_length\": 10,\n",
      "            \"embed_dim\": 512,\n",
      "            \"num_layers\": 6,\n",
      "            \"num_heads\": 8,\n",
      "            \"emb_dropout\": 0.1,\n",
      "            \"attn_dropout\": 0.1,\n",
      "            \"block_output_dropout\": 0.1,\n",
      "            \"sinusoidal_embedding\": false,\n",
      "            \"activation\": \"gelu\",\n",
      "            \"supervise_all_steps\": false,\n",
      "            \"nn_parameter_for_timesteps\": true,\n",
      "            \"pred_future_acs\": false,\n",
      "            \"causal\": true\n",
      "        },\n",
      "        \"language_conditioned\": false\n",
      "    },\n",
      "    \"observation\": {\n",
      "        \"modalities\": {\n",
      "            \"obs\": {\n",
      "                \"low_dim\": [\n",
      "                    \"actions\",\n",
      "                    \"goal_dof_pos_scaled\",\n",
      "                    \"goal_pos\",\n",
      "                    \"goal_quat\",\n",
      "                    \"hand_joint_pos\",\n",
      "                    \"hand_palm_pos\",\n",
      "                    \"hand_palm_quat\",\n",
      "                    \"object_dof_pos_scaled\",\n",
      "                    \"object_pos\",\n",
      "                    \"object_quat\",\n",
      "                    \"object_type\",\n",
      "                    \"object_type_one_hot\"\n",
      "                ],\n",
      "                \"rgb\": [\n",
      "                    \"hand_camera\"\n",
      "                ],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            },\n",
      "            \"goal\": {\n",
      "                \"low_dim\": [],\n",
      "                \"rgb\": [],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            }\n",
      "        },\n",
      "        \"encoder\": {\n",
      "            \"low_dim\": {\n",
      "                \"core_class\": null,\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"rgb\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {\n",
      "                    \"backbone_class\": \"ResNet18Conv\",\n",
      "                    \"backbone_kwargs\": {\n",
      "                        \"pretrained\": false,\n",
      "                        \"input_coord_conv\": false\n",
      "                    },\n",
      "                    \"pool_class\": \"SpatialSoftmax\",\n",
      "                    \"pool_kwargs\": {\n",
      "                        \"num_kp\": 32,\n",
      "                        \"learnable_temperature\": false,\n",
      "                        \"temperature\": 1.0,\n",
      "                        \"noise_std\": 0.0\n",
      "                    }\n",
      "                },\n",
      "                \"obs_randomizer_class\": \"CropRandomizer\",\n",
      "                \"obs_randomizer_kwargs\": {\n",
      "                    \"crop_height\": 19,\n",
      "                    \"crop_width\": 19,\n",
      "                    \"num_crops\": 1,\n",
      "                    \"pos_enc\": false\n",
      "                }\n",
      "            },\n",
      "            \"depth\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"scan\": {\n",
      "                \"core_class\": \"ScanCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"meta\": {\n",
      "        \"hp_base_config_file\": null,\n",
      "        \"hp_keys\": [],\n",
      "        \"hp_values\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['goal_dof_pos_scaled', 'hand_joint_pos', 'object_type', 'goal_quat', 'hand_palm_pos', 'object_dof_pos_scaled', 'goal_pos', 'object_quat', 'object_pos', 'hand_palm_quat', 'actions', 'object_type_one_hot']\n",
      "using obs modality: rgb with keys: ['hand_camera']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n",
      "============= Loaded Policy =============\n",
      "ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!\n",
      "BC (\n",
      "  ModuleDict(\n",
      "    (policy): ActorNetwork(\n",
      "        action_dim=22\n",
      "  \n",
      "        encoder=ObservationGroupEncoder(\n",
      "            group=obs\n",
      "            ObservationEncoder(\n",
      "                Key(\n",
      "                    name=actions\n",
      "                    shape=[22]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=goal_dof_pos_scaled\n",
      "                    shape=[1]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=goal_pos\n",
      "                    shape=[3]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=goal_quat\n",
      "                    shape=[4]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=hand_camera\n",
      "                    shape=[3, 64, 64]\n",
      "                    modality=rgb\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): CropRandomizer(input_shape=[3, 64, 64], crop_size=[19, 19], num_crops=1)\n",
      "                    )\n",
      "                    net=VisualCore(\n",
      "                      input_shape=[3, 19, 19]\n",
      "                      output_shape=[64]\n",
      "                      backbone_net=ResNet18Conv(input_channel=3, input_coord_conv=False)\n",
      "                      pool_net=SpatialSoftmax(num_kp=32, temperature=1.0, noise=0.0)\n",
      "                    )\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=hand_joint_pos\n",
      "                    shape=[22]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=hand_palm_pos\n",
      "                    shape=[3]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=hand_palm_quat\n",
      "                    shape=[4]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=object_dof_pos_scaled\n",
      "                    shape=[1]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=object_pos\n",
      "                    shape=[3]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=object_quat\n",
      "                    shape=[4]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=object_type\n",
      "                    shape=[1]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=object_type_one_hot\n",
      "                    shape=[7]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                output_shape=[139]\n",
      "            )\n",
      "        )\n",
      "  \n",
      "        mlp=MLP(\n",
      "            input_dim=139\n",
      "            output_dim=1024\n",
      "            layer_dims=[1024]\n",
      "            layer_func=Linear\n",
      "            dropout=None\n",
      "            act=ReLU\n",
      "            output_act=ReLU\n",
      "        )\n",
      "  \n",
      "        decoder=ObservationDecoder(\n",
      "            Key(\n",
      "                name=action\n",
      "                shape=(22,)\n",
      "                modality=low_dim\n",
      "                net=(Linear(in_features=1024, out_features=22, bias=True))\n",
      "            )\n",
      "        )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = TorchUtils.get_torch_device(try_to_use_cuda=True)\n",
    "\n",
    "# restore policy\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872a3f0",
   "metadata": {},
   "source": [
    "### Creating rollout envionment\n",
    "The policy checkpoint also contains sufficient information to recreate the environment that it's trained with. Again, you may manually create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d00c2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create environment from saved checkpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env, _ \u001b[38;5;241m=\u001b[39m \u001b[43mFileUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# we won't do on-screen rendering in the notebook\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# render to RGB images for video\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ngc/robomimic/robomimic/utils/file_utils.py:499\u001b[0m, in \u001b[0;36menv_from_checkpoint\u001b[0;34m(ckpt_path, ckpt_dict, env_name, render, render_offscreen, verbose)\u001b[0m\n\u001b[1;32m    496\u001b[0m shape_meta \u001b[38;5;241m=\u001b[39m ckpt_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# create env from saved metadata\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_env_from_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m config, _ \u001b[38;5;241m=\u001b[39m config_from_checkpoint(algo_name\u001b[38;5;241m=\u001b[39mckpt_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgo_name\u001b[39m\u001b[38;5;124m\"\u001b[39m], ckpt_dict\u001b[38;5;241m=\u001b[39mckpt_dict, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    506\u001b[0m env \u001b[38;5;241m=\u001b[39m EnvUtils\u001b[38;5;241m.\u001b[39mwrap_env_from_config(env, config\u001b[38;5;241m=\u001b[39mconfig) \u001b[38;5;66;03m# apply environment warpper, if applicable\u001b[39;00m\n",
      "File \u001b[0;32m~/ngc/robomimic/robomimic/utils/env_utils.py:219\u001b[0m, in \u001b[0;36mcreate_env_from_metadata\u001b[0;34m(env_meta, env_name, render, render_offscreen, use_image_obs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     env_name \u001b[38;5;241m=\u001b[39m env_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 219\u001b[0m env_type \u001b[38;5;241m=\u001b[39m \u001b[43mget_env_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m env_kwargs \u001b[38;5;241m=\u001b[39m env_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    221\u001b[0m env_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m env_name\n",
      "File \u001b[0;32m~/ngc/robomimic/robomimic/utils/env_utils.py:68\u001b[0m, in \u001b[0;36mget_env_type\u001b[0;34m(env_meta, env_type, env)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m(checks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould provide only one of env_meta, env_type, env\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env_meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     env_type \u001b[38;5;241m=\u001b[39m \u001b[43menv_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     env_type \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mtype\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "# create environment from saved checkpoint\n",
    "env, _ = FileUtils.env_from_checkpoint(\n",
    "    ckpt_dict=ckpt_dict, \n",
    "    render=False, # we won't do on-screen rendering in the notebook\n",
    "    render_offscreen=True, # render to RGB images for video\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5313e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = str(igenvs_root / \"isaacgymenvs\" / \"cfg\")\n",
    "overrides = [\"task=ArticulateTaskSprayScissorsCamera\", \"test=true\", \"num_envs=100\", \n",
    "             \"train=ArticulateTaskPPONew\"]\n",
    "with initialize_config_dir(config_dir=config_dir, version_base=\"1.3\"):\n",
    "    cfg_expert = compose(config_name=\"config.yaml\", overrides=overrides)\n",
    "# task_cfg = OmegaConf.load(igenvs_root / \"task\" / \"ArticulateTaskSprayScissors.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c8a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.0.1+cu118\n",
      "Device count 1\n",
      "/home/krishnans/carbgym/python/isaacgym/_bindings/src/gymtorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/krishnans/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/krishnans/.cache/torch_extensions/py38_cu118/gymtorch/build.ninja...\n",
      "Building extension module gymtorch...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module gymtorch...\n",
      "2024-04-04 05:34:39,337 - INFO - logger - logger initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:3: DeprecationWarning: invalid escape sequence \\*\n",
      "/home/krishnans/carbgym/python/isaacgym/torch_utils.py:135: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def get_axis_params(value, axis_idx, x_value=0., dtype=np.float, n_dims=3):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: FBX library failed to load - importing FBX data will not succeed. Message: No module named 'fbx'\n",
      "FBX tools must be installed from https://help.autodesk.com/view/FBX/2020/ENU/?guid=FBX_Developer_Help_scripting_with_python_fbx_installing_python_fbx_html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping\n",
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, Set, Iterable\n",
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/networkx/readwrite/graphml.py:346: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.int, \"int\"), (np.int8, \"int\"),\n",
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/articulate.py:477: DeprecationWarning: an integer is required (got type isaacgym._bindings.linux-x86_64.gym_38.DofDriveMode).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  asset_options.default_dof_drive_mode = gymapi.DOF_MODE_POS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] [carb.gym.plugin] useGpu is set, forcing single scene (0 subscenes)\n",
      "Not connected to PVD\n",
      "+++ Using GPU PhysX\n",
      "Physics Engine: PhysX\n",
      "Physics Device: cuda:0\n",
      "GPU Pipeline: enabled\n",
      "Num hand dofs:  22\n",
      "Using VHACD cache directory '/home/krishnans/.isaacgym/vhacd'\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 0, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 1, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 2, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 3, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 4, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 5, Body 1 ('link_3'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 15, Body 3 ('link_1'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 16, Body 3 ('link_1'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 17, Body 3 ('link_1'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 18, Body 3 ('link_1'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 19, Body 3 ('link_1'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 20, Body 3 ('link_1'))\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-10.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-11.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-12.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-13.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-14.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-16.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-17.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-19.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-20.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-8.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle/textured_objs/original-9.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-1.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-10.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-11.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-12.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-13.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-14.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-15.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-16.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-2.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-3.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-4.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-5.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-6.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-7.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-8.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/spray_bottle2/textured_objs/original-9.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/new-0.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/new-1.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/new-2.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/new-3.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/original-1.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/original-2.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/original-4.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/original-5.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors/textured_objs/original-7.obj'\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 3, Body 2 ('link_0'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 4, Body 2 ('link_0'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 5, Body 2 ('link_0'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 6, Body 2 ('link_0'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 7, Body 2 ('link_0'))\n",
      "[Warning] [carb.gym.plugin] Convex decomposition: Triangle meshes without a path cannot be cached at this time. (Shape 8, Body 2 ('link_0'))\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors2/textured_objs/new-1.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors2/textured_objs/new-6.obj'\n",
      "Found existing convex decomposition for mesh '/home/krishnans/diff_manip/external/IsaacGymEnvs/isaacgymenvs/tasks/../../assets/urdf/objects/scissors2/textured_objs/new-7.obj'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/carbgym/python/isaacgym/torch_utils.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n",
      "/home/krishnans/carbgym/python/isaacgym/torch_utils.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs dictionary: \n",
      "{'hand_joint_pos': [22], 'hand_joint_vel': [22], 'object_pos': [3], 'object_quat': [4], 'goal_pos': [3], 'goal_quat': [4], 'object_lin_vel': [3], 'object_ang_vel': [3], 'object_dof_pos': [1], 'goal_dof_pos': [1], 'hand_palm_pos': [3], 'hand_palm_quat': [4], 'object_type_one_hot': [7], 'object_instance_one_hot': [5], 'actions': [22], 'hand_camera': [64, 64, 3]}\n",
      "hand_joint_pos: [22]\n",
      "hand_joint_pos: torch.Size([100, 22])\n",
      "hand_joint_vel: [22]\n",
      "hand_joint_vel: torch.Size([100, 22])\n",
      "object_pos: [3]\n",
      "object_pos: torch.Size([100, 3])\n",
      "object_quat: [4]\n",
      "object_quat: torch.Size([100, 4])\n",
      "goal_pos: [3]\n",
      "goal_pos: torch.Size([100, 3])\n",
      "goal_quat: [4]\n",
      "goal_quat: torch.Size([100, 4])\n",
      "object_lin_vel: [3]\n",
      "object_lin_vel: torch.Size([100, 3])\n",
      "object_ang_vel: [3]\n",
      "object_ang_vel: torch.Size([100, 3])\n",
      "object_dof_pos: [1]\n",
      "object_dof_pos: torch.Size([100, 1])\n",
      "goal_dof_pos: [1]\n",
      "goal_dof_pos: torch.Size([100, 1])\n",
      "hand_palm_pos: [3]\n",
      "hand_palm_pos: torch.Size([100, 3])\n",
      "hand_palm_quat: [4]\n",
      "hand_palm_quat: torch.Size([100, 4])\n",
      "object_type_one_hot: [7]\n",
      "object_type_one_hot: torch.Size([100, 7])\n",
      "object_instance_one_hot: [5]\n",
      "object_instance_one_hot: torch.Size([100, 5])\n",
      "actions: [22]\n",
      "actions: torch.Size([100, 22])\n",
      "hand_camera: [64, 64, 3]\n",
      "hand_camera: torch.Size([100, 64, 64, 3])\n",
      "State dictionary: \n",
      "{}\n",
      "[Warning] [carb.gym.plugin] Acquiring DOF force tensor, but no actors have DOF force sensors enabled.\n",
      "[Warning] [carb.gym.plugin] -> Enabled DOF force sensors for all eligible actors.\n",
      "Num dofs:  23\n"
     ]
    }
   ],
   "source": [
    "# OmegaConf.load(\"../../bc_trained_models/test/20240403143734/config.yaml\")\n",
    "# (\"runs/articulate_scissors1_relac_expert/config.yaml\")\n",
    "env = isaacgymenvs.make(\n",
    "            cfg_expert.seed,\n",
    "            cfg_expert.task_name,\n",
    "            cfg_expert.task.env.numEnvs,\n",
    "            cfg_expert.sim_device,\n",
    "            cfg_expert.rl_device,\n",
    "            cfg_expert.graphics_device_id,\n",
    "            cfg_expert.headless,\n",
    "            cfg_expert.multi_gpu,\n",
    "            cfg_expert.capture_video,\n",
    "            cfg_expert.force_render,\n",
    "            cfg_expert,\n",
    "            # **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0e9f",
   "metadata": {},
   "source": [
    "### Define the rollout loop\n",
    "Now let's define the main rollout loop. The loop runs the policy to a target `horizon` and optionally writes the rollout to a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec9af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal_dof_pos_scaled', 'object_dof_pos_scaled', 'object_type'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs['obs'].keys()\n",
    "env.rollout_exceptions = ()\n",
    "set(policy.policy.nets.policy.obs_shapes.keys()) - set(obs['obs'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dd1375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(policy, env, horizon, render=False, video_writer=None, video_skip=5, camera_names=None):\n",
    "    \"\"\"\n",
    "    Helper function to carry out rollouts. Supports on-screen rendering, off-screen rendering to a video, \n",
    "    and returns the rollout trajectory.\n",
    "    Args:\n",
    "        policy (instance of RolloutPolicy): policy loaded from a checkpoint\n",
    "        env (instance of EnvBase): env loaded from a checkpoint or demonstration metadata\n",
    "        horizon (int): maximum horizon for the rollout\n",
    "        render (bool): whether to render rollout on-screen\n",
    "        video_writer (imageio writer): if provided, use to write rollout to video\n",
    "        video_skip (int): how often to write video frames\n",
    "        camera_names (list): determines which camera(s) are used for rendering. Pass more than\n",
    "            one to output a video with multiple camera views concatenated horizontally.\n",
    "    Returns:\n",
    "        stats (dict): some statistics for the rollout - such as return, horizon, and task success\n",
    "    \"\"\"\n",
    "    # assert isinstance(env, EnvBase)\n",
    "    assert isinstance(policy, RolloutPolicy)\n",
    "    assert not (render and (video_writer is not None))\n",
    "\n",
    "    policy.start_episode()\n",
    "    obs = env.reset()\n",
    "    obs_keys = set(policy.policy.nets.policy.obs_shapes.keys())\n",
    "    # state_dict = env.get_state()\n",
    "\n",
    "    # hack that is necessary for robosuite tasks for deterministic action playback\n",
    "    # obs = env.reset_to(state_dict)\n",
    "\n",
    "    results = {}\n",
    "    video_count = 0  # video frame counter\n",
    "    total_reward = 0.\n",
    "    try:\n",
    "        for step_i in range(horizon):\n",
    "            obs_dict = {}\n",
    "            for k in obs_keys:\n",
    "                if \"camera\" in k:\n",
    "                    obs_dict[k] = env.obs_dict[k].permute(0, 3, 1, 2)\n",
    "                    print(obs_dict[k].shape)\n",
    "                else:\n",
    "                    obs_dict[k] = env.obs_dict[k]\n",
    "\n",
    "            # get action from policy\n",
    "            act = policy(ob=obs_dict, batched=True)\n",
    "\n",
    "            # play action\n",
    "            next_obs, r, done, info = env.step(torch.tensor(act,device=env.device, dtype=torch.float))\n",
    "\n",
    "            # compute reward\n",
    "            total_reward += r\n",
    "            success = info[\"success\"] # env.is_success()[\"task\"]\n",
    "\n",
    "            # visualization\n",
    "            if render:\n",
    "                env.render(mode=\"human\", camera_name=camera_names[0])\n",
    "            if video_writer is not None:\n",
    "                if video_count % video_skip == 0:\n",
    "                    video_img = []\n",
    "                    for cam_name in camera_names:\n",
    "                        video_img.append(obs_dict[cam_name].cpu().numpy()[0])\n",
    "                    video_img = np.concatenate(video_img, axis=1) # concatenate horizontally\n",
    "                    video_writer.append_data(video_img)\n",
    "                video_count += 1\n",
    "\n",
    "            # break if done or if success\n",
    "            if done or success:\n",
    "                break\n",
    "\n",
    "            # update for next iter\n",
    "            obs = deepcopy(next_obs)\n",
    "            state_dict = env.get_state()\n",
    "\n",
    "    except env.rollout_exceptions as e:\n",
    "        print(\"WARNING: got rollout exception {}\".format(e))\n",
    "\n",
    "    stats = dict(Return=total_reward, Horizon=(step_i + 1), Success_Rate=float(success))\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43d371",
   "metadata": {},
   "source": [
    "### Run the policy\n",
    "Now let's rollout the policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be6e1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_horizon = 400\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "video_path = \"rollout.mp4\"\n",
    "video_writer = imageio.get_writer(video_path, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fa67efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/carbgym/python/isaacgym/torch_utils.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image must have 1, 2, 3 or 4 channels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrollout_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhand_camera\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(stats)\n\u001b[1;32m     11\u001b[0m video_writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[41], line 61\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(policy, env, horizon, render, video_writer, video_skip, camera_names)\u001b[0m\n\u001b[1;32m     59\u001b[0m             video_img\u001b[38;5;241m.\u001b[39mappend(obs_dict[cam_name]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     60\u001b[0m         video_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(video_img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# concatenate horizontally\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mvideo_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     video_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# break if done or if success\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robomimic/lib/python3.8/site-packages/imageio/core/format.py:590\u001b[0m, in \u001b[0;36mFormat.Writer.append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    588\u001b[0m im \u001b[38;5;241m=\u001b[39m asarray(im)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# Call\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_meta\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/robomimic/lib/python3.8/site-packages/imageio/plugins/ffmpeg.py:584\u001b[0m, in \u001b[0;36mFfmpegFormat.Writer._append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m\u001b[38;5;241m.\u001b[39mget(depth, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pix_fmt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage must have 1, 2, 3 or 4 channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_depth \u001b[38;5;241m=\u001b[39m depth\n",
      "\u001b[0;31mValueError\u001b[0m: Image must have 1, 2, 3 or 4 channels"
     ]
    }
   ],
   "source": [
    "stats = rollout(\n",
    "    policy=policy, \n",
    "    env=env, \n",
    "    horizon=rollout_horizon, \n",
    "    render=False, \n",
    "    video_writer=video_writer, \n",
    "    video_skip=5, \n",
    "    camera_names=[\"hand_camera\"]\n",
    ")\n",
    "print(stats)\n",
    "video_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79bc19",
   "metadata": {},
   "source": [
    "### Visualize the rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97472b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
