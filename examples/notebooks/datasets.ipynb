{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ab9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import gym\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import yaml\n",
    "import hydra\n",
    "import myosuite.envs.myo.myobase\n",
    "import omegaconf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a000d6",
   "metadata": {},
   "source": [
    "## Add task_id to bidex tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb5c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from robomimic_data import add_task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f43353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = glob.glob('/home/krishnans/ngc/DexterousHands/bidexhands/logs/ShadowHand**/**/**/rollout*0.hdf5')\n",
    "task_names = [\"switch\"] * 2 + [\"scissors\"] * 3\n",
    "task_set = 'bidex'\n",
    "\n",
    "add_task_id(data_paths, task_names, task_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a70204",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "switch the image channels to (c, h, w) if it is in the order of (h, w, c)\n",
    "'''\n",
    "def convert_hwc_to_chw(data):\n",
    "    if len(data.shape) >= 3 and data.shape[-1] < 5:\n",
    "        if type(data) == torch.tensor:\n",
    "            data = torch.moveaxis(data, -1, -3).contiguous()\n",
    "        elif type(data) == np.ndarray:\n",
    "            data = np.ascontiguousarray(np.moveaxis(data, -1, -3))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_articulate_to_robosuite(dataset_path, config_path=None):\n",
    "    config = {}\n",
    "    if config_path is not None:\n",
    "        config = yaml.safe_load(open(config_path, \"r\"))\n",
    "\n",
    "    with h5py.File(dataset_path, mode=\"a\") as data:\n",
    "        data.attrs[\"env_args\"] = json.dumps(config)\n",
    "        for ep in data[\"data\"].keys():\n",
    "            data[\"data/{}\".format(ep)].attrs[\"num_samples\"] = data[\"data/{}\".format(ep)][\"actions\"].shape[0]\n",
    "        # Create next_obs group for every demo in data, and copy obs/{key}.data[1:] to this group\n",
    "        for demo_key in data[\"data\"].keys():\n",
    "            demo_group = data[\"data\"][demo_key]\n",
    "            next_obs_group = demo_group.create_group(\"next_obs\")\n",
    "            \n",
    "            for obs_key in demo_group[\"obs\"].keys():\n",
    "                obs_data = demo_group[\"obs\"][obs_key]\n",
    "                next_obs_group.create_dataset(obs_key, data=obs_data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import robomimic.utils.file_utils as FileUtils\n",
    "\n",
    "# the dataset registry can be found at robomimic/__init__.py\n",
    "from robomimic import DATASET_REGISTRY\n",
    "\n",
    "# set download folder and make it\n",
    "download_folder = \"/tmp/robomimic_ds_example\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# download the dataset\n",
    "task = \"lift\"\n",
    "dataset_type = \"ph\"\n",
    "hdf5_type = \"low_dim\"\n",
    "FileUtils.download_url(\n",
    "    url=DATASET_REGISTRY[task][dataset_type][hdf5_type][\"url\"], \n",
    "    download_dir=download_folder,\n",
    ")\n",
    "\n",
    "# enforce that the dataset exists\n",
    "dataset_path = os.path.join(download_folder, \"low_dim_v141.hdf5\")\n",
    "assert os.path.exists(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdec82",
   "metadata": {},
   "source": [
    "## Read quantities from dataset\n",
    "\n",
    "Next, let's demonstrate how to read different quantities from the dataset. There are scripts such as `scripts/get_dataset_info.py` that can help you easily understand the contents of a dataset, but in this example, we'll break down how to do this directly.\n",
    "\n",
    "First, let's take a look at the number of demonstrations in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a323e6",
   "metadata": {},
   "source": [
    "```python\n",
    "dataset_path = \"/home/krishnans/ngc/policy_learning_toolkit/datasets/articulate_multi_spray_scissors/train/merged.hdf5\"\n",
    "dataset_path = \"/home/krishnans/ngc/DexterousHands/policy_learning_toolkit/train/bidex_runs/ShadowHandScissors/ppo/ppo_seed-1/rollouts_1000.hdf5\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ad48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myosuite task dataset paths\n",
    "dataset_root = Path(\"/juno/u/ksrini/multi_task_experts/datasets/myosuite\")\n",
    "dataset_path = list(dataset_root.iterdir())[0].absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35cd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 file /juno/u/ksrini/multi_task_experts/datasets/myosuite/myo-key-turn_100.hdf5 has 100 demonstrations\n"
     ]
    }
   ],
   "source": [
    "# open file\n",
    "f = h5py.File(dataset_path, \"r\")\n",
    "\n",
    "# each demonstration is a group under \"data\"\n",
    "demos = list(f[\"data\"].keys())\n",
    "num_demos = len(demos)\n",
    "\n",
    "print(\"hdf5 file {} has {} demonstrations\".format(dataset_path, num_demos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2ab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb073a0",
   "metadata": {},
   "source": [
    "Next, let's list all of the demonstrations, along with the number of state-action pairs in each demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bda3e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'actions' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m demos \u001b[38;5;241m=\u001b[39m [demos[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m demos:\n\u001b[0;32m----> 7\u001b[0m     num_actions \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/actions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ep, num_actions))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/scr-ssd/henryang/miniconda3/envs/multitask/lib/python3.8/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:241\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'actions' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# each demonstration is named \"demo_#\" where # is a number.\n",
    "# Let's put the demonstration list in increasing episode order\n",
    "inds = np.argsort([int(elem[5:]) for elem in demos])\n",
    "demos = [demos[i] for i in inds]\n",
    "\n",
    "for ep in demos:\n",
    "    num_actions = f[\"data/{}/actions\".format(ep)].shape[0]\n",
    "    print(\"{} has {} samples\".format(ep, num_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff998d62",
   "metadata": {},
   "source": [
    "Now, let's dig into a single trajectory to take a look at some of the quantities in each demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at first demonstration\n",
    "demo_key = demos[0]\n",
    "demo_grp = f[\"data/{}\".format(demo_key)]\n",
    "\n",
    "# Each observation is a dictionary that maps modalities to numpy arrays, and\n",
    "# each action is a numpy array. Let's print the observations and actions for the \n",
    "# first 5 timesteps of this trajectory.\n",
    "for t in range(5):\n",
    "    print(\"timestep {}\".format(t))\n",
    "    obs_t = dict()\n",
    "    # each observation modality is stored as a subgroup\n",
    "    for k in demo_grp[\"obs\"]:\n",
    "        obs_t[k] = demo_grp[\"obs/{}\".format(k)][t] # numpy array\n",
    "    act_t = demo_grp[\"action\"][t]\n",
    "    \n",
    "    # pretty-print observation and action using json\n",
    "    obs_t_pp = { k : obs_t[k].tolist() for k in obs_t }\n",
    "    print(\"obs\")\n",
    "    print(json.dumps(obs_t_pp, indent=4))\n",
    "    print(\"action\")\n",
    "    print(act_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047b5536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[234, 180, 133],\n",
       "        [233, 181, 134],\n",
       "        [233, 181, 134],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[229, 177, 131],\n",
       "        [231, 178, 132],\n",
       "        [235, 180, 133],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[233, 177, 131],\n",
       "        [233, 177, 130],\n",
       "        [236, 178, 130],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[230, 167, 118],\n",
       "        [231, 168, 119],\n",
       "        [232, 169, 120],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[236, 175, 125],\n",
       "        [236, 174, 124],\n",
       "        [236, 173, 124],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[228, 165, 116],\n",
       "        [227, 163, 114],\n",
       "        [226, 161, 112],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_grp['obs']['fixed_camera'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552be387",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'actions' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we can also grab multiple timesteps at once directly, or even the full trajectory at once\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m first_ten_actions \u001b[38;5;241m=\u001b[39m \u001b[43mdemo_grp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of first ten actions \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(first_ten_actions\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m      4\u001b[0m all_actions \u001b[38;5;241m=\u001b[39m demo_grp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/scr-ssd/henryang/miniconda3/envs/multitask/lib/python3.8/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:241\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'actions' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# we can also grab multiple timesteps at once directly, or even the full trajectory at once\n",
    "first_ten_actions = demo_grp[\"actions\"][:10]\n",
    "print(\"shape of first ten actions {}\".format(first_ten_actions.shape))\n",
    "all_actions = demo_grp[\"actions\"][:]\n",
    "print(\"shape of all actions {}\".format(all_actions.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e59b01",
   "metadata": {},
   "source": [
    "# Dataset helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c146d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, yaml\n",
    "\n",
    "def merge_hdf5_files(source_files, target_file):\n",
    "    \"\"\"\n",
    "    Merge multiple HDF5 files into a single file, ensuring that \"data/demo_X\" keys\n",
    "    are unique across the merged file.\n",
    "\n",
    "    Args:\n",
    "        source_files (list of str): List of paths to source HDF5 files to merge.\n",
    "        target_file (str): Path to the target HDF5 file to create.\n",
    "    \"\"\"\n",
    "    with h5py.File(target_file, 'w') as target_h5:\n",
    "        if \"data\" not in target_h5.keys():\n",
    "            target_h5.create_group(\"data\")  # Ensure the 'data' group exists in the target file\n",
    "        for source_file in source_files:\n",
    "            with h5py.File(source_file, 'r') as source_h5:\n",
    "                # Iterate over each \"demo_X\" group in the source file\n",
    "                for key in source_h5['data'].keys():\n",
    "                    # Extract the demo number from the key and increment it by the current offset\n",
    "                    new_demo_key = f'demo_{len(target_h5[\"data\"].keys())}'\n",
    "\n",
    "                    # Copy the group to the new file with the updated demo key\n",
    "                    source_h5.copy(f'data/{key}', target_h5[\"data\"], new_demo_key)\n",
    "\n",
    "\n",
    "def convert_camera_obs_hwc(source_file, target_file):\n",
    "    \"\"\"\n",
    "    Convert all observations with the name \"camera\" in the key from (c, h, w) to (h, w, c) shape ordering,\n",
    "    and change dtype to np.uint8 for a single source file, and map it to a target file.\n",
    "\n",
    "    Args:\n",
    "        source_file (str): Path to the source HDF5 file.\n",
    "        target_file (str): Path to the target HDF5 file to create.\n",
    "    \"\"\"\n",
    "    with h5py.File(source_file, 'r') as source_h5:\n",
    "        with h5py.File(target_file, 'w') as target_h5:\n",
    "            # Iterate over each \"demo_X\" group in the source file\n",
    "            for demo_key in source_h5['data'].keys():\n",
    "                demo_group = source_h5['data'][demo_key]\n",
    "                target_demo_group = target_h5.require_group(f'data/{demo_key}')\n",
    "                \n",
    "                # Check if the \"obs\" group exists in the demo group\n",
    "                for key in demo_group:\n",
    "                    if key == \"obs\":\n",
    "                        obs_group = demo_group[\"obs\"]\n",
    "                        # Add \"obs\" group to the target_demo_group if it doesn't already exist\n",
    "                        target_demo_group.create_group(\"obs\")\n",
    "                        # Iterate over each item in the \"obs\" group\n",
    "                        for item_key in obs_group.keys():\n",
    "                            item = obs_group[item_key]\n",
    "                            \n",
    "                            # Check if the item is an observation with \"camera\" in the key\n",
    "                            if \"camera\" in item_key and len(item.shape) == 4:  # Assuming shape is (timesteps, c, h, w)\n",
    "                                # Convert (c, h, w) to (h, w, c) and change dtype to np.uint8\n",
    "                                converted_item = item[:].transpose(0, 2, 3, 1).astype(np.uint8)\n",
    "                                target_demo_group[\"obs\"].create_dataset(item_key, data=converted_item)\n",
    "                            else:\n",
    "                                # For other items within \"obs\", just copy them as they are\n",
    "                                obs_group.copy(item_key, target_demo_group[\"obs\"])\n",
    "                    else:\n",
    "                        demo_group.copy(f'{key}', target_demo_group, key)\n",
    "                        # target_demo_group.create_dataset(key, data=demo_group[key])\n",
    "\n",
    "\n",
    "def convert_articulate_to_robosuite(dataset_path, config_path=None):\n",
    "    config = {}\n",
    "    if config_path is not None:\n",
    "        config = yaml.safe_load(open(config_path, \"r\"))\n",
    "\n",
    "    with h5py.File(dataset_path, mode=\"a\") as data:\n",
    "        data.attrs[\"env_args\"] = json.dumps(config)\n",
    "        for ep in data[\"data\"].keys():\n",
    "            data[\"data/{}\".format(ep)].attrs[\"num_samples\"] = data[\"data/{}\".format(ep)][\"actions\"].shape[0]\n",
    "\n",
    "MYOSUITE_TASKS = {\n",
    "\t'myo-reach': 'myoHandReachFixed-v0',\n",
    "\t'myo-reach-hard': 'myoHandReachRandom-v0',\n",
    "\t'myo-pose': 'myoHandPoseFixed-v0',\n",
    "\t'myo-pose-hard': 'myoHandPoseRandom-v0',\n",
    "\t'myo-obj-hold': 'myoHandObjHoldFixed-v0',\n",
    "\t'myo-obj-hold-hard': 'myoHandObjHoldRandom-v0',\n",
    "\t'myo-key-turn': 'myoHandKeyTurnFixed-v0',\n",
    "\t'myo-key-turn-hard': 'myoHandKeyTurnRandom-v0',\n",
    "\t'myo-pen-twirl': 'myoHandPenTwirlFixed-v0',\n",
    "\t'myo-pen-twirl-hard': 'myoHandPenTwirlRandom-v0',\n",
    "}\n",
    "\n",
    "def add_mask(dataset_paths):\n",
    "    \"\"\"Adds a mask to the dataset to indicate which demonstrations are successful.\n",
    "    A demonstration is successful if it has at least one sample.\"\"\"\n",
    "    for dataset_path in dataset_paths:\n",
    "        cfg = omegaconf.OmegaConf.load(dataset_paths[0].parent/'.hydra/config.yaml')\n",
    "        min_ep_len = gym.envs.registry.spec(MYOSUITE_TASKS[cfg.task]).max_episode_steps + 1\n",
    "        with h5py.File(dataset_path, \"a\") as data:\n",
    "            success_demos = []\n",
    "            for ep in data[\"data\"].keys():\n",
    "                        if data[f\"data/{ep}\"].attrs['num_samples'] >= 1:\n",
    "                            success_demos.append(ep.encode('utf-8'))  # HDF5 requires bytes for strings\n",
    "            if \"mask\" not in data.keys():\n",
    "                data.create_group(\"mask\")\n",
    "            if \"traj_success\" not in data[\"mask\"].keys():\n",
    "                data[\"mask\"].create_dataset(\"traj_success\", data=np.array(success_demos, dtype=h5py.string_dtype(encoding='utf-8')))\n",
    "            else:\n",
    "                print(f\"skipping mask for {dataset_path}, traj_success already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84229edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demo_0', 'demo_1', 'demo_10', 'demo_11', 'demo_12', 'demo_13', 'demo_14', 'demo_15', 'demo_16', 'demo_17', 'demo_18', 'demo_19', 'demo_2', 'demo_20', 'demo_21', 'demo_22', 'demo_23', 'demo_24', 'demo_25', 'demo_26', 'demo_27', 'demo_28', 'demo_29', 'demo_3', 'demo_30', 'demo_31', 'demo_32', 'demo_33', 'demo_34', 'demo_35', 'demo_36', 'demo_37', 'demo_38', 'demo_39', 'demo_4', 'demo_40', 'demo_41', 'demo_42', 'demo_43', 'demo_44', 'demo_45', 'demo_46', 'demo_47', 'demo_48', 'demo_49', 'demo_5', 'demo_50', 'demo_51', 'demo_52', 'demo_53', 'demo_54', 'demo_55', 'demo_56', 'demo_57', 'demo_58', 'demo_59', 'demo_6', 'demo_60', 'demo_61', 'demo_62', 'demo_63', 'demo_64', 'demo_65', 'demo_66', 'demo_67', 'demo_68', 'demo_69', 'demo_7', 'demo_70', 'demo_71', 'demo_72', 'demo_73', 'demo_74', 'demo_75', 'demo_76', 'demo_77', 'demo_78', 'demo_79', 'demo_8', 'demo_80', 'demo_81', 'demo_82', 'demo_83', 'demo_84', 'demo_85', 'demo_86', 'demo_87', 'demo_88', 'demo_89', 'demo_9', 'demo_90', 'demo_91', 'demo_92', 'demo_93', 'demo_94', 'demo_95', 'demo_96', 'demo_97', 'demo_98', 'demo_99']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(dataset_path, \"r\") as data:\n",
    "    print([s.decode('utf-8') for s in data['mask']['traj_success']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009c46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksrini_hdf5_dir = Path('/juno/u/ksrini/multi_task_experts/collect_myosuite/multirun/2024-05-19')\n",
    "henryang_hdf5_dir = Path('/juno/u/henryang/multi_task_experts/collect_myosuite/outputs/2024-05-18')\n",
    "k_paths = list(ksrini_hdf5_dir.rglob(pattern='*.hdf5'))\n",
    "h_paths = list(henryang_hdf5_dir.rglob(pattern='*.hdf5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792e3868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping mask for /juno/u/henryang/multi_task_experts/collect_myosuite/outputs/2024-05-18/17-25-38/myo-reach_100.hdf5, traj_success already exists\n",
      "skipping mask for /juno/u/henryang/multi_task_experts/collect_myosuite/outputs/2024-05-18/17-09-21/myo-key-turn_100.hdf5, traj_success already exists\n"
     ]
    }
   ],
   "source": [
    "add_mask(h_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db0b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping mask for /juno/u/ksrini/multi_task_experts/collect_myosuite/multirun/2024-05-19/00-07-27/0/myo-obj-hold-hard_500.hdf5, traj_success already exists\n"
     ]
    }
   ],
   "source": [
    "add_mask(k_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e88e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ksrini iprl 16831859452 May 19 02:20 /juno/u/ksrini/multi_task_experts/collect_myosuite/multirun/2024-05-19/00-07-27/0/myo-obj-hold-hard_500.hdf5\n"
     ]
    }
   ],
   "source": [
    "ls -al /juno/u/ksrini/multi_task_experts/collect_myosuite/multirun/2024-05-19/00-07-27/0/myo-obj-hold-hard_500.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c078fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "robo_formatted_file = dataset_path #  os.path.join(os.path.split(dataset_path)[0], \"merge_robosuite.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(robo_formatted_file) as data:\n",
    "    for ep in data[\"data\"].keys():\n",
    "        print(f\"{ep} num samples\", data[f\"data/{ep}\"].attrs[\"num_samples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2490fc",
   "metadata": {},
   "source": [
    "## Loading and running bidex task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaacgym, isaacgymenvs\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import compose, initialize_config_dir\n",
    "from isaacgymenvs.utils.rlgames_utils import get_rlgames_env_creator\n",
    "from isaacgymenvs.utils.reformat import omegaconf_to_dict\n",
    "\n",
    "def get_expert_cfg(config_path=None, checkpoint_path=None):\n",
    "    if checkpoint_path:\n",
    "        config_path = os.path.join(os.path.dirname(os.path.dirname(checkpoint_path)), \"config.yaml\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = OmegaConf.load(config_path)\n",
    "    return cfg\n",
    "\n",
    "cfg_expert = get_expert_cfg(\"/mnt/ws-dmanip/isaacgymenvs/isaacgymenvs/runs/ArticulateSpray2Expert_12-20-34-27/config.yaml\")\n",
    "\n",
    "create_rlgpu_env = get_rlgames_env_creator(\n",
    "    cfg_expert['seed'],\n",
    "    omegaconf_to_dict(cfg_expert[\"task\"]),\n",
    "    cfg_expert[\"task_name\"],\n",
    "    cfg_expert[\"sim_device\"],\n",
    "    cfg_expert[\"rl_device\"],\n",
    "    cfg_expert['graphics_device_id'],\n",
    "    cfg_expert['headless'],\n",
    "    multi_gpu=cfg_expert['multi_gpu'],\n",
    "    )\n",
    "\n",
    "env = create_rlgpu_env()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.dirname(dataset_path)\n",
    "source_files = list(filter(lambda x: not x.startswith(\"merged\"), map(lambda x: os.path.join(dataset_dir, x), os.listdir(dataset_dir))))\n",
    "# merge all hdf5 files in dataset_path into a single hdf5 file\n",
    "merged_dataset_path = os.path.join(os.path.dirname(dataset_path), \"merged.hdf5\")\n",
    "if not os.path.exists(merged_dataset_path):\n",
    "    # os.remove(merged_dataset_path)\n",
    "    merge_hdf5_files(source_files, merged_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(merged_dataset_path, \"r\") as f:\n",
    "    print(\"merged dataset has {} demonstrations\".format(len(f[\"data\"].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93687dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "f = h5py.File(merged_dataset_path, \"a\")\n",
    "\n",
    "# each demonstration is a group under \"data\"\n",
    "demos = list(f[\"data\"].keys())\n",
    "num_demos = len(demos)\n",
    "demo_grp = f[\"data\"][demos[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_keys = demo_grp[\"obs\"].keys()\n",
    "# demo_grp.create_group(\"next_obs\")\n",
    "for k in obs_keys:\n",
    "    demo_grp.create_dataset(f\"next_obs/{k}\", data=demo_grp[f\"obs/{k}\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57976238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trajectory also contains the next observations under \"next_obs\", \n",
    "# for convenient use in a batch (offline) RL pipeline. Let's verify\n",
    "# that \"next_obs\" and \"obs\" are offset by 1.\n",
    "for k in demo_grp[\"obs\"]:\n",
    "    # obs_{t+1} == next_obs_{t}\n",
    "    assert(np.allclose(demo_grp[\"obs\"][k][1:], demo_grp[\"next_obs\"][k][:-1]))\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_articulate_to_robosuite(merged_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also have \"done\" and \"reward\" information stored in each trajectory.\n",
    "# In this case, we have sparse rewards that indicate task completion at\n",
    "# that timestep.\n",
    "dones = demo_grp[\"dones\"][:]\n",
    "rewards = demo_grp[\"rewards\"][:]\n",
    "print(\"dones\")\n",
    "print(dones)\n",
    "print(\"\")\n",
    "print(\"rewards\")\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360df27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each demonstration also contains metadata\n",
    "num_samples = demo_grp.attrs[\"num_samples\"] # number of samples in this trajectory\n",
    "mujoco_xml_file = demo_grp.attrs[\"model_file\"] # mujoco XML file for this demonstration\n",
    "print(mujoco_xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10f98f",
   "metadata": {},
   "source": [
    "Finally, let's take a look at some global metadata present in the file. The hdf5 file stores environment metadata which is a convenient way to understand which simulation environment (task) the dataset was collected on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b579caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_meta = json.loads(f[\"data\"].attrs[\"env_args\"])\n",
    "# note: we could also have used the following function:\n",
    "# env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path=dataset_path)\n",
    "print(\"==== Env Meta ====\")\n",
    "print(json.dumps(env_meta, indent=4))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395453a",
   "metadata": {},
   "source": [
    "## Visualizing demonstration trajectories\n",
    "\n",
    "Finally, let's play some of these demonstrations back in the simulation environment to easily visualize the data that was collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613ab93",
   "metadata": {},
   "source": [
    "It turns out that the environment metadata stored in the hdf5 allows us to easily create a simulation environment that is consistent with the way the dataset was collected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import robomimic.utils.env_utils as EnvUtils\n",
    "\n",
    "# create simulation environment from environment metedata\n",
    "env = EnvUtils.create_env_from_metadata(\n",
    "    env_meta=env_meta, \n",
    "    render=False,            # no on-screen rendering\n",
    "    render_offscreen=True,   # off-screen rendering to support rendering video frames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "\n",
    "# We normally need to make sure robomimic knows which observations are images (for the\n",
    "# data processing pipeline). This is usually inferred from your training config, but\n",
    "# since we are just playing back demonstrations, we just need to initialize robomimic\n",
    "# with a dummy spec.\n",
    "dummy_spec = dict(\n",
    "    obs=dict(\n",
    "            low_dim=[\"robot0_eef_pos\"],\n",
    "            rgb=[],\n",
    "        ),\n",
    ")\n",
    "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# prepare to write playback trajectories to video\n",
    "video_path = os.path.join(download_folder, \"playback.mp4\")\n",
    "video_writer = imageio.get_writer(video_path, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playback_trajectory(demo_key):\n",
    "    \"\"\"\n",
    "    Simple helper function to playback the trajectory stored under the hdf5 group @demo_key and\n",
    "    write frames rendered from the simulation to the active @video_writer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # robosuite datasets store the ground-truth simulator states under the \"states\" key.\n",
    "    # We will use the first one, alone with the model xml, to reset the environment to\n",
    "    # the initial configuration before playing back actions.\n",
    "    init_state = f[\"data/{}/states\".format(demo_key)][0]\n",
    "    model_xml = f[\"data/{}\".format(demo_key)].attrs[\"model_file\"]\n",
    "    initial_state_dict = dict(states=init_state, model=model_xml)\n",
    "    \n",
    "    # reset to initial state\n",
    "    env.reset_to(initial_state_dict)\n",
    "    \n",
    "    # playback actions one by one, and render frames\n",
    "    actions = f[\"data/{}/actions\".format(demo_key)][:]\n",
    "    for t in range(actions.shape[0]):\n",
    "        env.step(actions[t])\n",
    "        video_img = env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"agentview\")\n",
    "        video_writer.append_data(video_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playback the first 5 demos\n",
    "for ep in demos[:5]:\n",
    "    print(\"Playing back demo key: {}\".format(ep))\n",
    "    playback_trajectory(ep)\n",
    "\n",
    "# done writing video\n",
    "video_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the trajectories!\n",
    "from IPython.display import Video\n",
    "Video(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea881c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
